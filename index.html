<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.4d42fdfc2eef5083b696.css" data-identity="gatsby-global-css">/*
! tailwindcss v3.0.8 | MIT License | https://tailwindcss.com
*/*,:after,:before{border:0 solid;box-sizing:border-box}:after,:before{--tw-content:""}html{-webkit-text-size-adjust:100%;font-family:ui-sans-serif,system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4}body{line-height:inherit;margin:0}hr{border-top-width:1px;color:inherit;height:0}abbr:where([title]){-webkit-text-decoration:underline dotted;text-decoration:underline dotted}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}b,strong{font-weight:bolder}code,kbd,pre,samp{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}table{border-collapse:collapse;border-color:inherit;text-indent:0}button,input,optgroup,select,textarea{color:inherit;font-family:inherit;font-size:100%;line-height:inherit;margin:0;padding:0}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button;background-color:transparent;background-image:none}:-moz-focusring{outline:auto}:-moz-ui-invalid{box-shadow:none}progress{vertical-align:baseline}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}summary{display:list-item}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}fieldset{margin:0}fieldset,legend{padding:0}menu,ol,ul{list-style:none;margin:0;padding:0}textarea{resize:vertical}input::-moz-placeholder,textarea::-moz-placeholder{color:#9ca3af;opacity:1}input:-ms-input-placeholder,textarea:-ms-input-placeholder{color:#9ca3af;opacity:1}input::placeholder,textarea::placeholder{color:#9ca3af;opacity:1}[role=button],button{cursor:pointer}:disabled{cursor:default}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{height:auto;max-width:100%}[hidden]{display:none}.fixed{position:fixed}.mx-auto{margin-left:auto;margin-right:auto}.mr-5{margin-right:1.25rem}.ml-3{margin-left:.75rem}.mt-3{margin-top:.75rem}.mt-12{margin-top:3rem}.mb-8{margin-bottom:2rem}.mt-5{margin-top:1.25rem}.flex{display:flex}.hidden{display:none}.h-12{height:3rem}.h-48{height:12rem}.w-full{width:100%}.max-w-screen-md{max-width:768px}.max-w-screen-lg{max-width:1024px}.flex-1{flex:1 1 0%}.list-disc{list-style-type:disc}.flex-row{flex-direction:row}.flex-wrap{flex-wrap:wrap}.content-center{align-content:center}.items-center{align-items:center}.items-baseline{align-items:baseline}.bg-black{--tw-bg-opacity:1;background-color:rgb(0 0 0/var(--tw-bg-opacity))}.bg-gray-200{--tw-bg-opacity:1;background-color:rgb(229 231 235/var(--tw-bg-opacity))}.px-5{padding-left:1.25rem;padding-right:1.25rem}.py-16{padding-bottom:4rem;padding-top:4rem}.py-3{padding-bottom:.75rem;padding-top:.75rem}.pl-10{padding-left:2.5rem}.pt-16{padding-top:4rem}.text-center{text-align:center}.text-justify{text-align:justify}.text-sm{font-size:.875rem;line-height:1.25rem}.text-xs{font-size:.75rem;line-height:1rem}.text-xl{font-size:1.25rem;line-height:1.75rem}.font-bold{font-weight:700}.font-semibold{font-weight:600}.text-blue-600{--tw-text-opacity:1;color:rgb(37 99 235/var(--tw-text-opacity))}.text-white{--tw-text-opacity:1;color:rgb(255 255 255/var(--tw-text-opacity))}.text-gray-300{--tw-text-opacity:1;color:rgb(209 213 219/var(--tw-text-opacity))}.text-gray-600{--tw-text-opacity:1;color:rgb(75 85 99/var(--tw-text-opacity))}.text-blue-800{--tw-text-opacity:1;color:rgb(30 64 175/var(--tw-text-opacity))}.text-gray-500{--tw-text-opacity:1;color:rgb(107 114 128/var(--tw-text-opacity))}@media (min-width:768px){.md\:mt-0{margin-top:0}.md\:ml-5{margin-left:1.25rem}.md\:block{display:block}.md\:w-60{width:15rem}.md\:pt-28{padding-top:7rem}}</style><meta name="generator" content="Gatsby 4.4.0"/><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){if(void 0===e.target.dataset.mainImage)return;if(void 0===e.target.dataset.gatsbyImageSsr)return;const t=e.target;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><title data-react-helmet="true"></title><link rel="sitemap" type="application/xml" href="/sitemap/sitemap-index.xml"/><link rel="icon" href="/favicon-32x32.png?v=53aa06cf17e4239d0dba6ffd09854e02" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=53aa06cf17e4239d0dba6ffd09854e02"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=53aa06cf17e4239d0dba6ffd09854e02"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=53aa06cf17e4239d0dba6ffd09854e02"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=53aa06cf17e4239d0dba6ffd09854e02"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=53aa06cf17e4239d0dba6ffd09854e02"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=53aa06cf17e4239d0dba6ffd09854e02"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=53aa06cf17e4239d0dba6ffd09854e02"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=53aa06cf17e4239d0dba6ffd09854e02"/><link as="script" rel="preload" href="/webpack-runtime-eeb24cc78a6f6e7e0a6a.js"/><link as="script" rel="preload" href="/framework-5aba6dc98ac29269aae0.js"/><link as="script" rel="preload" href="/app-f4756d18539972e693c4.js"/><link as="script" rel="preload" href="/component---src-pages-index-js-f71270d618976512c393.js"/><link as="fetch" rel="preload" href="/page-data/index/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><main style="color:#232129;font-family:Georgia, Times New Roman, Times, serif"><div class="bg-black h-12 text-white fixed w-full"><div class="max-w-screen-md max-w-screen-lg mx-auto px-5"><div class="h-12 flex flex-row flex-wrap content-center items-baseline"><div class="mr-5 font-bold"><a href="#top">Yan Pang</a></div><div class="mr-5 text-sm text-gray-300 hidden md:block"><a href="#interest">Research Interests</a></div><div class="mr-5 text-sm text-gray-300 hidden md:block"><a href="#news">News</a></div><div class="mr-5 text-sm text-gray-300 hidden md:block"><a href="#educations">Educations</a></div><div class="mr-5 text-sm text-gray-300 hidden md:block"><a href="#publications">Publications</a></div><div class="mr-5 text-sm text-gray-300 hidden md:block"><a href="#presentations"> Invited Talks</a></div><div class="mr-5 text-sm text-gray-300 hidden md:block"><a href="#patents">Patents</a></div><div class="mr-5 text-sm text-gray-300 hidden md:block"><a href="#teaching">Teaching Experiences</a></div><div class="mr-5 text-sm text-gray-300 hidden md:block"><a href="#students">Students</a></div></div></div></div><div id="top"></div><div><div class="max-w-screen-md max-w-screen-lg mx-auto px-5 py-16 md:pt-28"><div class="flex flex-row flex-wrap"><div><img class="w-full md:w-60" src="https://pbs.twimg.com/media/FH6H1i4UUAEyhAN?format=jpg&amp;name=medium"/></div><div class="flex-1 ml-3 mt-3 md:mt-0 text-justify"><p class="mt-3"><b>Associate Professor</b> at the <b>Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences</b>, China. </p><p class="mt-3">Dr. Pang earned his Ph.D. from the University of Colorado in 2021. His research focuses on computer vision, smart healthcare, and embodied intelligent surgical robot navigation systems. Between September 2022 and September 2025, he served as an associate professor at Guangzhou University in China. Prior to this, Dr. Pang worked as a machine learning scientist at Moffett AI in Los Altos, CA, from April 2021 to May 2022. He also held instructor positions at the University of Colorado Denver (Department of Electrical Engineering) and Metropolitan State University of Denver (Department of Electrical Engineering Technology) from August 2018 to May 2021.</p><div class="mt-3 text-xs text-gray-600"><div> <span class="font-bold">Address:</span> 1068 Xueyuan Avenue, Shenzhen University Town, Shenzhen, 518055 China | <span class="font-bold">Email:</span> yan.pang@siat.ac.cn</div></div></div></div><div id="interests" class="mt-12"><div class="text-blue-800 text-xl font-bold">Research Interests</div><p class="text-sm">My research focuses on the broad areas of machine learning, deep learning and their applications on computer vision. Specifically, I focus on </p><div class="text-sm pl-10 py-3"><ul class="list-disc"><li>Medical Image Analysis</li><li>Embodied Intelligent Surgical Robot</li><li>Large-scale Vision Models</li><li>On-device Models</li><li>Graph Neural Networks</li><li>Semantic Segmentation</li><li>Key Points Detection</li><li>Blockchain Security</li><li>Photography</li></ul></div></div><div id="news"><div class="text-blue-800 text-xl font-bold">News</div><div class="text-sm pl-10 py-3 text-justify"><ul class="list-disc"><li>[Feb 14, 2026] <b>NEW:</b> One paper has been published in the Expert Systems with Applications. (IF: 7.5).  <a class="text-blue-600 text-sm" href="https://github.com/deepang-ai/OCTMamba" target="_blank">Code</a> is released.</li><li>[Jan 13, 2026] <b>NEW:</b> One paper has been published in the IEEE Transactions on Medical Imaging. (IF: 9.8).  <a class="text-blue-600 text-sm" href="https://github.com/deepang-ai/UltraMamba" target="_blank">Code</a> is released.</li><li>[Oct 09, 2025] Joined to Chinese Academy of Sciences.</li><li>[Sep 29, 2025] One paper has been published in the IEEE Transactions on Medical Imaging. (IF: 9.8).  <a class="text-blue-600 text-sm" href="https://github.com/deepang-ai/EAT" target="_blank">Code</a> is released.</li><li>[Sep 05, 2025] One paper has been published in the IEEE Journal of Biomedical and Health Informatics. (IF: 7.7).  <a class="text-blue-600 text-sm" href="https://github.com/deepang-ai/SegTom" target="_blank">Code</a> is released.</li><li>[Aug 25, 2025] One paper has been published in the IEEE Transactions on Medical Imaging. (IF: 9.8).  <a class="text-blue-600 text-sm" href="https://github.com/deepang-ai/Slim-UNETRV2" target="_blank">Code</a> is released.</li><li>[Aug 23, 2025] ğŸ‰ Success! Papers 1614, 1833, and 2000 from our group are presented at <a class="text-blue-600 text-sm" href="http://2025.prcv.cn/" target="_blank">PRCV 2025</a> in Shanghai. Proud of my students&#x27; contributions to the field! </li><li>[Jul 30, 2025] One paper has been published in the IEEE Transactions on Big Data. (IF: 5.7).  <a class="text-blue-600 text-sm" href="https://github.com/deepang-ai/Consense" target="_blank">Code</a> is released.</li><li>[Jul 14, 2025] One paper has been published in the IEEE Transactions on Information Forensics and Security. (IF: 8).  <a class="text-blue-600 text-sm" href="https://github.com/deepang-ai/SAMamba" target="_blank">Code</a> is released.</li><li>[Jun 17, 2025] One paper has been published in the IEEE Transactions on Systems, Man and Cybernetics: Systems. (IF: 8.7).  <a class="text-blue-600 text-sm" href="https://github.com/deepang-ai/LGA" target="_blank">Code</a> is released.</li><li>[Feb 19, 2025] One paper has been published in the IEEE Journal of Biomedical and Health Informatics. (IF: 7.7).  <a class="text-blue-600 text-sm" href="https://github.com/deepang-ai/BaS" target="_blank">Code</a> is released.</li><li>[Jan 16, 2025] One paper has been published in the IEEE Journal of Biomedical and Health Informatics. (IF: 7.7).  <a class="text-blue-600 text-sm" href="https://github.com/deepang-ai/MOD" target="_blank">Code</a> is released.</li><li>[Dec 12, 2024] <b>NEW:</b> Welcome to submit your papers to our special topics &quot;<a class="text-blue-600 text-sm" href="https://www.mdpi.com/topics/0ZZS608U21" target="_blank">AI and Data-Driven Advancements in Industry 4.0, 2nd Edition</a>&quot;.</li><li>[Oct 19, 2024] Honored to be named one of the best ACs for PRCV2024! Excited to contribute to this leading conference in computer vision.</li><li>[Oct 18, 2024] ğŸ‰ Success! Papers 1458, 1464, and 1468 from our group are presented at <a class="text-blue-600 text-sm" href="http://2024.prcv.cn/" target="_blank">PRCV 2024</a> in Urumqi. Proud of my students&#x27; contributions to the field! </li><li>[Apr 21, 2024] One paper has been published in the Journal of IEEE Transactions on Instrumentation and Measurement. (IF: 5.6).  <a class="text-blue-600 text-sm" href="https://github.com/deepang-ai/AdaptFormer" target="_blank">Code</a> is released.</li><li>[Oct 20, 2023] One paper has been published in the Journal of IEEE Transactions on Medical Imaging. (IF: 10.6).  <a class="text-blue-600 text-sm" href="https://github.com/deepang-ai/Slim-UNETR" target="_blank">Code</a> is released.</li><li>[Aug 14, 2023] One paper has been published in the Journal of IEEE Transactions on Neural Networks and Learning Systems. (IF: 10.4).</li><li>[Feb 07, 2023] One paper published in the Journal of Information Sciences (IF: 8.233).</li><li>[Jan 06, 2023] Become a topic editor of the &quot;<a class="text-blue-600 text-sm" href="https://www.mdpi.com/topics/FLN51J9SH1" target="_blank">AI and Data-Driven Advancements in Industry 4.0</a>&quot;. Welcome to submit your papers on AI.</li><li>[Aug 15, 2022] Joined to Guangzhou University, Guangdong.</li><li>[Jul 25, 2022] Two papers published in the International Journal of Intelligent Systems ï¼ˆIFï¼š8.993ï¼‰.</li><li>[Dec 18, 2021] Received my Ph.D. degree.</li><li>[Aug 01, 2021] One paper published in the Journal of Geophysical Research Letters (IF: 5.58). </li><li>[Apr 12, 2021] Joined to Moffett AI, Los Altos, CA.</li><li>[Nov 01, 2020] One paper has been published in the Journal of Computers and Electronics in Agriculture. </li><li>[Mar 01, 2020] One paper has been published in the Journal of Neuroscience Methods. </li><li>[Apr 24, 2019] One paper is accepted to Science and Information Conference</li></ul></div></div><div id="educations"><div class="text-blue-800 text-xl font-bold">Educations</div><div class="text-sm pl-10 py-3"><ul class="list-disc"><li>2017.08 - 2021.12, University of Colorado, Dept. of Electrical Engineering, Ph.D.</li><li>2015.08 - 2017.05, University of Wyoming, Dept. of Electrical and Computer Engineering, Ph.D. Student</li><li>2010.09 - 2013.05, Politecnico di Torino, Dept. of Electrical Engineering, Master</li><li>2005.09 - 2009.05, Henan Polytechnic University, Dept. of Automation, Bachelor</li></ul></div></div><div id="publications"><div class="text-blue-800 text-xl font-bold">Journal Publications</div><div class="py-3"><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div> Jiahui Huang, Junming Yan, Qiong Wang, Qingjie Meng, Jinpeng Li, <span class="font-bold">Yan Pang*</span></div></div><div class="font-bold">OCTMamba: A Lightweight Ear Segmentation Framework for 3D Portable Endoscopic OCT Scanner</div><div>Expert Systems with Applications</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1016/j.eswa.2026.131678" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div> Jiahui Huang, Jiaxin Huang, Mingdu Zhang, Qiong Wang, Xiao-Qing Pei, Ying Hu, Hao Chen, <span class="font-bold">Yan Pang*</span></div></div><div class="font-bold">UltraMamba: Mamba-based Multimodal Ultrasound Image Adaptive Fusion for Breast Lesion Segmentation</div><div>IEEE Transactions on Medical Imaging</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1109/TMI.2026.3653779" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div><span class="font-bold">Yan Pang</span>, Yucheng Long, Zibin Chen, Ying Hu, Hao Chen, Qiong Wang</div></div><div class="font-bold">Endoscopic Adaptive Transformer for Enhanced Polyp Segmentation in Endoscopic Imaging</div><div>IEEE Transactions on Medical Imaging</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1109/TMI.2025.3615677" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div><span class="font-bold">Yan Pang</span>, Yunhao Li, Jiaming Liang, Hao Chen, Ying Hu, Qiong Wang</div></div><div class="font-bold">SegTom: A 3D Volumetric Medical Image Segmentation Framework for Thoracoabdominal Multi-Organ Anatomical Structures</div><div>IEEE Journal of Biomedical and Health Informatics</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1109/JBHI.2025.3606266" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div><span class="font-bold">Yan Pang</span>, Jiaming Liang, Junming Yan, Ying Hu, Hao Chen, Qiong Wang</div></div><div class="font-bold">Slim UNETRV2: 3D Image Segmentation for Resource-Limited Medical Portable Devices</div><div>IEEE Transactions on Medical Imaging</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1109/TMI.2025.3602145" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div> <span class="font-bold">Yan Pang</span>, Xiangfu Liu, Teng Huang, Yile Hong, Jiahui Huang, Changyu Dong</div></div><div class="font-bold">Graph-based Contract Sensing Framework for Smart Contract Vulnerability Detection</div><div>IEEE Transactions on Big Data</div><div><a class="text-blue-600 text-sm" href="https://ieeexplore.ieee.org/document/11104930" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div> Teng Huang, Jiahui Huang, Changyu Dong, Sisi Duan, <span class="font-bold">Yan Pang*</span></div></div><div class="font-bold">SAMamba: Structure-Aware Mamba for Ethereum Fraud Detection</div><div>IEEE Transactions on Information Forensics and Security</div><div><a class="text-blue-600 text-sm" href="https://ieeexplore.ieee.org/document/11080015" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div> Jiahui Huang, Teng Huang, Changyu Dong, Sisi Duan, <span class="font-bold">Yan Pang*</span></div></div><div class="font-bold">Hierarchical Network with Local-Global Awareness for Ethereum Account De-anonymization</div><div>IEEE Transactions on Systems, Man and Cybernetics: Systems</div><div><a class="text-blue-600 text-sm" href="https://ieeexplore.ieee.org/document/11037616" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div> <span class="font-bold">Yan Pang</span>, Yunhao Li, Teng Huang, Jiaming Liang, Ziyu Ding, Hao Chen, Baoliang Zhao, Ying Hu, Zheng Zhang, Qiong Wang</div></div><div class="font-bold">Efficient Breast Lesion Segmentation from Ultrasound Videos Across Multiple Source-limited Platforms</div><div>IEEE Journal of Biomedical and Health Informatics</div><div><a class="text-blue-600 text-sm" href="https://ieeexplore.ieee.org/document/10892059" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div> <span class="font-bold">Yan Pang</span>, Yunhao Li, Teng Huang, Jiaming Liang, Zhen Wang, Changyu Dong, Dongyang Kuang, Ying Hu, Hao Chen, Tim Lei, Qiong Wang</div></div><div class="font-bold">Online Self-distillation and Self-modeling for 3D Brain Tumor Segmentation</div><div>IEEE Journal of Biomedical and Health Informatics</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1109/JBHI.2025.3530715" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div>Teng Huang, Yile Hong, <span class="font-bold">Yan Pang*</span>, Jiaming Liang, Jie Hong, Lin Huang, Yuan Zhang, Yan Jia, Patrizia Savi</div></div><div class="font-bold">AdaptFormer: An Adaptive Hierarchical Semantic Approach for Change Detection on Remote Sensing Images</div><div>IEEE Transactions on Instrumentation and Measurement</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1109/TIM.2024.3387494" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div><span class="font-bold">Yan Pang</span>, Jiaming Liang, Teng Huang, Hao Chen, Yunhao Li, Dan Li, Lin Huang, Qiong Wang</div></div><div class="font-bold">Slim UNETR: Scale Hybrid Transformers to Efficient 3D Medical Image Segmentation Under Limited Computational Resources</div><div>IEEE Transactions on Medical Imaging</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1109/TMI.2023.3326188" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div>Zhen Wang, Yang Zhang, <span class="font-bold">Yan Pang*</span>, Nannan Wang, Mohamed Jaward Bah, Ke Li, Ji Zhang</div></div><div class="font-bold">Toward Learning Joint Inference Tasks for IASS-MTS Using Dual Attention Memory With Stochastic Generative Imputation</div><div>IEEE Transactions on Neural Networks and Learning Systems</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1109/TNNLS.2023.3305542" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div>Teng Huang, Jiahui Huang, <span class="font-bold">Yan Pang*</span>, Hongyang Yan</div></div><div class="font-bold">Smart Contract Watermarking Based on Code Obfuscation</div><div>Information Sciences</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1016/j.ins.2023.01.126" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div><span class="font-bold">Yan Pang</span>, Ai Shan, Zhen Wang, Mengyu Wang, Jianwei Li, Ji Zhang, Teng Huang, Chao Liu </div></div><div class="font-bold">Sparse-Dyn: Sparse dynamic graph multirepresentation learning via event-based sparse temporal attention network</div><div>International Journal of Intelligent Systems</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1002/int.22967" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div><span class="font-bold">Yan Pang</span>, Teng Huang, Zhen Wang, Jianwei Li, Poorya Hosseini, Ji Zhang, Chao Liu, Shan Ai </div></div><div class="font-bold">Graph Decipher: A transparent dual-attention graph neural network to understand the message-passing mechanism for the node classification</div><div>International Journal of Intelligent Systems</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1002/int.22966" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div> Vijay Harid, Chao Liu, <span class="font-bold">Yan Pang</span>, Akimun Jannat Alvina, Mark Golkowski, Poorya Hosseini, Morris Cohen</div></div><div class="font-bold">Automated Largeâ€Scale Extraction of Whistlers Using Maskâ€Scoring Regional Convolutional Neural Network</div><div>Geophysical Research Letters</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1029/2021GL093819" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div><span class="font-bold">Yan Pang</span>, Yeyin Shi, Shancheng Gao, Feng Jiang, Arun-Narenthiran Veeranampalayam-Sivakumar, Laura Thompson, Joe Luck, Chao Liu</div></div><div class="font-bold">Improved crop row detection with deep neural network for early-season maize stand count in UAV imagery</div><div>Computers and Electronics in Agriculture</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1016/j.compag.2020.105766" target="_blank">Paper Link</a></div></div></div><div class="mb-8 flex flex-row flex-wrap items-center"><div class="md:ml-5 flex-1"><div><div><span class="font-bold">Yan Pang</span>, Jake Christenson, Feng Jiang, Tim Lei, Remy Rhoades, Drew Kern, John A Thompson, Chao Liu </div></div><div class="font-bold">Automatic detection and quantification of hand movements toward development of an objective assessment of tremor and bradykinesia in Parkinson&#x27;s disease</div><div>Journal of neuroscience methods</div><div><a class="text-blue-600 text-sm" href="https://doi.org/10.1016/j.jneumeth.2019.108576" target="_blank">Paper Link</a></div></div></div></div></div><div id="presentations"><div class="text-blue-800 text-xl font-bold">Invited Talks</div><div class="text-sm pl-10 py-3"><ul class="list-disc"><li>[Feb 07th, 202] Nanjing, China:<div>â€œCutting-Edge Technological Advances in Embodied Intelligence for Surgical Roboticsâ€, 18th International Conference on Machine Learning and Computing;</div></li><li>[Dec 21st, 2025] Guangzhou, China:<div>â€œResearch Progress in Medical Artificial Intelligence and Surgical Roboticsâ€, Academic Annual Conference of Guangdong Research-based Medicine Association;</div></li><li>[Sep 19th, 2025] Jinan, China:<div>â€œReal-Time Medical Image Processing via On-Device Model Architectures Integrated on AI Chipsâ€, China Association of Chinese Medicine;</div></li><li>[Jul 20th, 2025] Shenzhen, China:<div>â€œEmbodied Intelligent Surgical Robots: A Paradigm Shift from Passive Tools to Active Partnersâ€, South China Hospital of Shenzhen University;</div></li><li>[Feb 15th, 2025] Guangzhou, China:<div>â€œEnabling Real-Time Medical Imaging on Edge Devices: Co-Optimizing Accuracy and Computational Efficiencyâ€, 17th International Conference on Machine Learning and Computing 2025;</div></li><li>[May 25th, 2024] Haikou, China:<div>â€œOptimizing Medical Image Analysis: Boosting Model Performance with Integrated Software and Hardware Solutionsâ€, International Conference on Digital Image Processing 2024;</div></li><li>[Apr 14, 2024] Hangzhou, China:<div>â€œImproving Medical Image Analysis by Balancing Accuracy and Efficiency on Resource-Constrained Platformsâ€, The 3rd National Conference on Electronic Information Materials and Devices;</div></li><li>[Feb. 05th, 2024] Shenzhen, China:<div>â€œEnhancing Medical Image Analysis by Achieving an Optimal Balance Between Accuracy and Efficiency in Resource-Limited Platformsâ€, 16th International Conference on Machine Learning and Computing;</div></li><li>[Dec. 22nd, 2023] Shanghai, China:<div>â€œAdaptive Hierarchical Semantic Approach for Change Detectionâ€, The 9th International Conference on Signal Processing;</div></li><li>[Dec. 12th, 2023] Macao, China:<div>â€œOptimizing Machine Learning Algorithms for Coordinated Software and Hardware Performanceâ€, University of Macao;</div></li><li>[Dec. 01st, 2023] Luoyang, China:<div>â€œApplication of Large-scale Model of Multimodal Medical Image Analysisâ€, The First Affiliated Hospital of Henan University of Science &amp; Technology;</div></li><li>[Jun. 07th, 2023] Zhuhai, China:<div>â€œAdaptive Graph Representation Learningâ€, Sun Yat-Sen University;</div></li></ul></div></div><div id="patents"><div class="text-blue-800 text-xl font-bold">Patents</div><div class="text-sm pl-10 py-3"><ul class="list-disc"><li>ä¸€ç§æ–‡æœ¬ç”Ÿæˆç²¤å‰§è§†é¢‘çš„æ–¹æ³•ã€è£…ç½®ã€ç”µå­è®¾å¤‡åŠä»‹è´¨ï¼Œæˆæƒå·: ZL202411065751.1</li><li>åŸºäºå¤šæ¨¡æ€å›¾åƒçš„è„ŠæŸ±æ£€æµ‹æ–¹æ³•ã€è£…ç½®ã€è®¾å¤‡åŠå­˜å‚¨ä»‹è´¨ï¼Œæˆæƒå·: ZL202411752951.4</li><li>ä¸€ç§åŒ»å­¦å›¾åƒåˆ†å‰²æ–¹æ³•ã€è£…ç½®åŠä»‹è´¨ï¼Œæˆæƒå·: ZL202410616680.3</li><li>ç”¨æˆ·èº«ä»½è¯†åˆ«æ–¹æ³•ã€ç³»ç»Ÿã€è®¾å¤‡åŠå­˜å‚¨ä»‹è´¨, æˆæƒå·: ZL202410633064.9</li><li>é˜²å¾¡æ¨¡å‹è¢«çªƒå–æ”»å‡»çš„æ–¹æ³•ã€ç³»ç»Ÿã€è®¾å¤‡åŠå­˜å‚¨ä»‹è´¨, æˆæƒå·: ZL202410456738.2 </li><li>è‡ªè’¸é¦ä¸è‡ªå­¦ä¹ çš„åŒ»å­¦å›¾åƒåˆ†å‰²æ–¹æ³•ã€è£…ç½®åŠå­˜å‚¨ä»‹è´¨, æˆæƒå·: ZL202410615709.6 </li><li>åŒ»å­¦è§†é¢‘ä¹³è…ºç—…å˜ç‰¹å¾å¿«é€Ÿåˆ†å‰²æ–¹æ³•ã€è£…ç½®ã€è®¾å¤‡åŠä»‹è´¨, æˆæƒå·: ZL202410485386.3 </li><li>åŸºäºæ ‡è®°ç§»é™¤ç½‘ç»œçš„é«˜ç²¾åº¦é’¢ç´æ‰‹åŠ¿æ•°æ®é›†æ„å»ºæ–¹æ³•, æˆæƒå·: ZL202411072622.5 </li><li>å›¾åƒè¯†åˆ«æ–¹æ³•ã€è£…ç½®ã€è®¾å¤‡åŠå­˜å‚¨ä»‹è´¨, æˆæƒå·: ZL202410623942.9 </li><li>æ™ºèƒ½åˆçº¦çš„æ¼æ´æ£€æµ‹æ–¹æ³•ã€è£…ç½®ã€è®¾å¤‡åŠä»‹è´¨, æˆæƒå·: ZL202410547779.2 </li></ul></div></div><div id="teaching"><div class="text-blue-800 text-xl font-bold">Teaching Experiences</div><div class="text-sm pl-10 py-3"><ul class="list-disc"><li>2022.09 - 2025.09 Guangzhou University:<div>Computer Vision Processing(181940016-1), Natural Language Processing(180600065-1)ï¼ŒAssembly Language Processing(210600058-1).</div></li><li>2018.08 - 2021.05, Metropolitan State University of Denver:<div>EET/CPE 2350 Advanced Technical Programming, EET/CPE 3330 Digital Circuits/Systems II, EET/CPE 4020 Digital Circuits/Systems III, CPE 4600 VLSI Circuits and Systems.</div></li><li>2017.08 - 2021.05, University of Colorado Denver:<div>ELEC 4561 Hardware and Software Interface, ELEC 2531 Logic Lab.</div></li></ul></div></div><div id="students"><div class="text-blue-800 text-xl font-bold">Students</div><p class="text-sm font-bold">  Masters: </p><div class="text-sm pl-10 py-3"><ul class="list-disc"><li>Graduates of 2024: Jie Hongï¼ˆæ¸¯ç§‘å¹¿ï¼‰, Dan Liï¼ˆå¹¿æ¾èŒï¼‰, <a class="text-blue-600 text-sm" href="https://jeming-creater.github.io/" target="_blank">Jiaming Liangï¼ˆåå—ç†å·¥ï¼‰</a></li><li>Graduates of 2025: <a class="text-blue-600 text-sm" href="https://yunhaoli.top/" target="_blank">Yunhao Liï¼ˆé¦™æ¸¯ç†å·¥ï¼‰</a>, Yile Hongï¼ˆå¾—çŸ¥æ™ºèƒ½ï¼‰, Hui Liï¼ˆå“è¶Šæ•™è‚²ï¼‰, Mingwei Chenï¼ˆå†œå•†é“¶è¡Œï¼‰, Weiqing Kongï¼ˆå°é¹æ±½è½¦ï¼‰</li><li>Third-Year Student: Caiyan Tan, Junming Yan, Mingdu Zhang, Xiangfu Liu, Zibin Chen</li><li>Second-Year Student: Aoying Wang, Xin Wang</li><li>First-Year Student: <a class="text-blue-600 text-sm" href="https://leixin.me/" target="_blank">Xin Lei</a>, Xinyu Li, Qinjian Yan</li></ul></div></div></div><div class="h-48 bg-gray-200 text-center pt-16 text-sm text-gray-500"><div>Â© 2026 Yan Pang. All rights reserved</div><div>(Last update: Feb 14, 2026.)</div></div></div></main></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-6a71d9fc662cbda582e6.js"],"app":["/app-f4756d18539972e693c4.js"],"component---src-pages-404-js":["/component---src-pages-404-js-00e77064645ae1056ad6.js"],"component---src-pages-index-js":["/component---src-pages-index-js-f71270d618976512c393.js"],"component---src-pages-index-old-js":["/component---src-pages-index-old-js-550796386d2c7103a1d8.js"]};/*]]>*/</script><script src="/polyfill-6a71d9fc662cbda582e6.js" nomodule=""></script><script src="/component---src-pages-index-js-f71270d618976512c393.js" async=""></script><script src="/app-f4756d18539972e693c4.js" async=""></script><script src="/framework-5aba6dc98ac29269aae0.js" async=""></script><script src="/webpack-runtime-eeb24cc78a6f6e7e0a6a.js" async=""></script></body></html>